{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# Import required libraries\n","import numpy as np # numpy is used for handling numerical operations on arrays\n","import pandas as pd # pandas is used for handling and manipulating structured data\n","from torchvision.io import read_image # For reading image data from a file\n","from torch.utils.data import Dataset, DataLoader # For creating custom datasets and dataloaders\n","from torchvision.transforms import ToTensor \n","import torch # PyTorch library for neural network operations\n","import torchvision # a package consists of popular datasets, model architectures, and common image transformations for computer vision.\n","from torchvision import transforms # for performing transformations on our dataset\n","import matplotlib.pyplot as plt # for plotting graphs and visualizing data\n","from torch.utils.data import random_split # for splitting the dataset into train and validation\n","import os # useful for operating system operations\n","\n","# Define the custom dataset\n","class MNISTxCIFAR(Dataset):\n","    def __init__(self, img_dir, transform=None, train=True):\n","        self.img_dir = img_dir # The directory where our images are stored\n","        self.transform = transform # The transformations to be applied on the images\n","        self.labels = [] # List to hold the labels of the images\n","\n","        if train: # If this is the training set\n","            self.classes = os.listdir(img_dir) # Get the list of classes (folders) in the directory\n","            self.classes.sort() # Sort the classes for consistency\n","            self.img_paths = [] # List to hold the paths of the images\n","            self.labels = [] # Reset the labels list\n","            for c in self.classes: # For each class\n","                c_dir = os.path.join(img_dir, c) # Get the directory of the class\n","                c_imgs = os.listdir(c_dir) # Get the list of images in the class directory\n","                for img in c_imgs: # For each image\n","                    self.img_paths.append(os.path.join(c_dir, img)) # Add the path of the image to the list\n","                    self.labels.append(int(c)) # Add the class label to the labels list\n","        else: # If this is the test set\n","            self.img_paths = [os.path.join(img_dir, img) for img in os.listdir(img_dir)] \n","            self.img_paths.sort()\n","            # No labels are included for the test set\n","\n","    def __len__(self):\n","        return len(self.img_paths) # The length of the dataset is the number of images\n","\n","    def __getitem__(self, idx): # Method to get an item from the dataset\n","        img_path = self.img_paths[idx] # Get the path of the image\n","        image = read_image(img_path) # Read the image from the path\n","        if self.transform: # If there are any transformations to be applied\n","            image = self.transform(image) # Apply the transformations\n","        if self.labels: # If there are labels\n","            return image, self.labels[idx] # Return the image and its label\n","        else:\n","            return image  # For the test set, we return just the image\n","\n","# Training and testing transformations\n","train_transform = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.ToTensor(), #TODO: Convert to tensor\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","test_transform = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.ToTensor(), #TODO: Convert to tensor\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","train_dir = \"/kaggle/input/mnistxcifar-competition-oxford/MNISTxCIFAR/train\"\n","test_dir = \"/kaggle/input/mnistxcifar-competition-oxford/MNISTxCIFAR/test\"\n","\n","# Load the training data\n","full_train_dataset = MNISTxCIFAR(train_dir, transform=train_transform) # Create the full training dataset\n","\n","# Split the full training dataset into training and validation sets\n","# Let's say we want to use 80% of the samples for training and 20% for validation\n","\n","# TODO: Split the dataset based on 80-20 split\n","train_size = int(0.8 * len(full_train_dataset))  # 80% of the dataset size\n","val_size = len(full_train_dataset) - train_size  # The remaining samples\n","\n","train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n","\n","# Batch_size\n","batch_size = 32\n","\n","# Create data loaders \n","# TODO: Fill in the loader parameters\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True) # Create the training dataloader\n","val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False) # Create the validation dataloader\n","\n","# Load the test data\n","# TODO: Fill in the loader parameters\n","test_dataset = MNISTxCIFAR(test_dir, train=False, transform=test_transform) # Create the test dataset\n","test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False) # Create the test dataloader\n","\n","# Check out the datasets\n","for images, labels in train_dataloader: # For each batch in the training dataloader\n","    print(images.shape, labels.shape) # Print the shapes of the images and labels tensors\n","    break # Stop after the first batch\n","\n","for images, labels in val_dataloader: # For each batch in the validation dataloader\n","    print(images.shape, labels.shape) # Print the shapes of the images and labels tensors\n","    break # Stop after the first batch\n","\n","for images in test_dataloader: # For each batch in the test dataloader\n","    print(images.shape) # Print the shape of the images tensor\n","    break # Stop after the first batch"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def imshow(inp, mean, std, title=None):\n","    \"\"\"Imshow for Tensor after reversing normalization.\"\"\"\n","    inp = inp.numpy().transpose((1, 2, 0))\n","    # Reverse the normalization\n","    inp = std * inp + mean\n","    inp = np.clip(inp, 0, 1)\n","    plt.imshow(inp)\n","    if title is not None:\n","        plt.title(title)\n","    plt.pause(0.001)\n","\n","mean = np.array([0.485, 0.456, 0.406])\n","std = np.array([0.229, 0.224, 0.225])\n","\n","\n","# Create a subplot grid of 10 rows and 6 columns (total 60 subplots)\n","fig, axs = plt.subplots(10, 6, figsize=(10, 20))  # 10 classes, 6 images each\n","\n","# Flatten the array of Axes instances for easy iteration\n","axs = axs.ravel()\n","\n","# Dictionary to hold images of each class\n","class_images = {}\n","\n","# Iterate over batches of images and labels in the training dataloader\n","for images, labels in train_dataloader:\n","    # Iterate over individual images and labels in the batch\n","    for img, label in zip(images, labels):\n","        label = label.item()  # Convert the label tensor to a Python scalar\n","        if label not in class_images:  # If this class hasn't been seen before\n","            class_images[label] = []  # Create a new list for this class\n","        if len(class_images[label]) < 6:  # If fewer than 6 images have been collected for this class\n","            class_images[label].append(img)  # Add the current image to the class's list\n","        if all(len(imgs) >= 6 for imgs in class_images.values()):  # If 6 images have been collected for all classes\n","            break  # Break out of the loop over images and labels\n","    else:  # If the loop over images and labels wasn't broken\n","        continue  # Continue with the next batch\n","    break  # If the loop over images and labels was broken, break the loop over batches\n","\n","\n","# Iterate over the collected images of each class\n","for label, imgs in class_images.items():\n","    for i, img in enumerate(imgs):  # For each image\n","        img = img.numpy().transpose((1, 2, 0))  # Convert to numpy array and transpose\n","        img = std * img + mean  # Reverse normalization\n","        img = np.clip(img, 0, 1)  # Clip values to range [0, 1]\n","        axs[label*6 + i].imshow(img)  # Display the image in the appropriate subplot\n","        axs[label*6 + i].axis('off')  # Turn off the axis\n","        if i == 0:  # For the first image of each class\n","            axs[label*6 + i].set_title(f'Class: {label}')  # Set the subplot's title to the class label\n","plt.show()  # Display the plot"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import models\n","from torch.optim import lr_scheduler\n","import torch.nn.functional as F\n","from tqdm import tqdm\n","from torchsummary import summary\n","\n","class MyNetwork(nn.Module):\n","    # Create your neural network!\n","    def __init__(self, input_shape, in_channels, num_classes):\n","        super(MyNetwork, self).__init__()\n","        \n","        self.conv1 = nn.Conv2d(in_channels = in_channels, out_channels = 16, kernel_size = 5, padding = 2, stride = 1)\n","        self.bn1 = nn.BatchNorm2d(16)\n","        self.pool1 = nn.MaxPool2d(2, 2)\n","        \n","        self.conv2 = nn.Conv2d(16, 32, 5, padding = 2, stride = 1)\n","        self.bn2 = nn.BatchNorm2d(32)\n","        self.pool2 = nn.MaxPool2d(2, 2)\n","        \n","        self.conv3 = nn.Conv2d(32, 64, 5, padding = 2, stride = 1)\n","        self.bn3 = nn.BatchNorm2d(64)\n","        self.pool3 = nn.MaxPool2d(2, 2)\n","        \n","        self.fc1 = nn.Linear(64 * (input_shape//8)*(input_shape//8), 256)\n","        self.fc2 = nn.Linear(256, 128)\n","        self.fc3 = nn.Linear(128, 64)\n","        self.fc4 = nn.Linear(64, 32)\n","        self.fc5 = nn.Linear(32, 16)\n","        self.fc_out = nn.Linear(16, num_classes)\n","\n","        self.activation = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.pool1(self.activation(self.bn1(self.conv1(x))))\n","        x = self.pool2(self.activation(self.bn2(self.conv2(x))))\n","        x = self.pool3(self.activation(self.bn3(self.conv3(x))))\n","\n","        x = x.view(x.size(0), -1)\n","\n","        x = F.dropout(self.activation(self.fc1(x)), p=0.5, training=self.training)\n","        x = F.dropout(self.activation(self.fc2(x)), p=0.5, training=self.training)\n","        x = F.dropout(self.activation(self.fc3(x)), p=0.5, training=self.training)\n","        x = F.dropout(self.activation(self.fc4(x)), p=0.5, training=self.training)\n","        x = self.activation(self.fc5(x))\n","        output = self.fc_out(x)\n","        return output\n","\n","# model instance\n","model = MyNetwork(input_shape = input_shape, in_channels = in_channels, num_classes = num_classes)\n","\n","# Move model to GPU if available\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","\n","# Loss function and optimizer\n","# TODO: Select a criterion and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.AdamW(model.parameters(), lr=0.001)\n","\n","# Learning rate scheduler\n","scheduler = lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.1)\n","\n","# Training loop\n","# TODO: Select your training epochs\n","\n","num_epochs = 16\n","for epoch in range(num_epochs):\n","    print(f\"Epoch {epoch+1}/{num_epochs}\")\n","    model.train()\n","\n","    for inputs, labels in tqdm(train_dataloader):\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","        \n","        # Zero the parameter gradients\n","        optimizer.zero_grad()\n","        \n","        # Forward pass through the model\n","        outputs = model(inputs)\n","        \n","        # Compute the loss\n","        loss = criterion(outputs, labels)\n","        \n","        # Backward + optimize\n","        loss.backward()\n","        optimizer.step()\n","    \n","    # Update the learning rate\n","    scheduler.step()\n","\n","    # Check performance on validation set\n","    model.eval()\n","    val_loss = 0.0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for inputs, labels in tqdm(val_dataloader):\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            \n","            # Forward pass through the model\n","            outputs = model(inputs)\n","            \n","            # Get the model predictions\n","            _, predicted = torch.max(outputs.data, 1)\n","            \n","            # Compute the accuracy\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","    \n","    val_loss = val_loss / total\n","    accuracy = 100 * correct / total\n","    \n","    # Print the accuracy\n","    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {accuracy:.2f}%\")\n","\n","print('Training complete')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["'''\n","Do not change this cell! This does the test predictions for you needed for evaluation.\n","'''\n","\n","import pandas as pd\n","\n","# Placeholder for your predictions and image identifiers\n","predictions = []\n","image_ids = []\n","\n","model.eval()\n","# Iterate over test set\n","for image in test_dataloader:\n","    image = image.cuda()\n","    \n","    with torch.no_grad():\n","        # Predict the label using your model (modify this as needed)\n","        pred = model(image)\n","    \n","    # Convert scores to class predictions\n","    pred = pred.argmax(dim=1)\n","\n","    # Append to our lists\n","    predictions.extend(pred.tolist())\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["'''\n","Do not change this cell! This appends your predictions to a submission csv file to get your score.\n","'''\n","\n","indices = list(range(len(predictions)))\n","indices = ['{:07d}'.format(i) for i in indices]\n","\n","# Create DataFrame\n","df = pd.DataFrame({\n","    'ID': indices,  # convert tensor to list\n","    'Label': predictions\n","})\n","\n","# Save DataFrame as CSV without headers\n","df.to_csv('submission.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n","        self.bn1 = nn.BatchNorm2d(32)\n","        self.pool1 = nn.MaxPool2d(2, 2)\n","        \n","        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n","        self.bn2 = nn.BatchNorm2d(64)\n","        self.pool2 = nn.MaxPool2d(2, 2)\n","        \n","        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n","        self.bn3 = nn.BatchNorm2d(128)\n","        self.pool3 = nn.MaxPool2d(2, 2)\n","\n","        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n","        self.bn4 = nn.BatchNorm2d(256)\n","        self.pool4 = nn.MaxPool2d(2, 2)\n","\n","        self.conv5 = nn.Conv2d(256, 512, 3, padding=1)\n","        self.bn5 = nn.BatchNorm2d(512)\n","        self.pool5 = nn.MaxPool2d(2, 2)\n","        \n","        self.fc1 = nn.Linear(512 * 1 * 1, 256)\n","        self.fc2 = nn.Linear(256, 128)\n","        self.fc3 = nn.Linear(128, 64)\n","        self.fc4 = nn.Linear(64, 32)\n","        self.fc_out = nn.Linear(32, 10)\n","\n","        self.activation = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.pool1(self.activation(self.bn1(self.conv1(x))))\n","        x = self.pool2(self.activation(self.bn2(self.conv2(x))))\n","        x = self.pool3(self.activation(self.bn3(self.conv3(x))))\n","        x = self.pool4(self.activation(self.bn4(self.conv4(x))))\n","        x = self.pool5(self.activation(self.bn5(self.conv5(x))))\n","\n","        x = x.view(x.size(0), -1)\n","\n","        x = F.dropout(self.activation(self.fc1(x)), p=0.5, training=self.training)\n","        x = F.dropout(self.activation(self.fc2(x)), p=0.5, training=self.training)\n","        x = F.dropout(self.activation(self.fc3(x)), p=0.5, training=self.training)\n","        x = self.activation(self.fc4(x))\n","        output = self.fc_out(x)\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import models\n","from torch.optim import lr_scheduler\n","import torch.nn.functional as F\n","from tqdm import tqdm\n","from torch.optim.lr_scheduler import ExponentialLR\n","\n","class MyNetwork(nn.Module):\n","    # Create your neural network!\n","    def __init__(self):\n","        super(MyNetwork, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 6, 5, padding = 2)\n","        self.pool1 = nn.MaxPool2d(2, 2)\n","        \n","        self.conv2 = nn.Conv2d(6, 16, 5, padding = 2)\n","        self.pool2 = nn.MaxPool2d(2, 2)\n","        \n","        self.conv3 = nn.Conv2d(16, 32, 5, padding = 2)\n","        self.pool3 = nn.MaxPool2d(2, 2)\n","\n","        self.conv4 = nn.Conv2d(32, 64, 5, padding = 2)\n","        self.pool4 = nn.MaxPool2d(2, 2)\n","\n","        self.conv5 = nn.Conv2d(64, 128, 5, padding = 2)\n","        self.pool5 = nn.MaxPool2d(2, 2)\n","        \n","        self.fc1 = nn.Linear(128 * 1 * 1, 120)\n","        self.fc2 = nn.Linear(120, 90)\n","        self.fc3 = nn.Linear(90, 64)\n","        self.fc4 = nn.Linear(64, 32)\n","        self.fc_out = nn.Linear(32, 10)\n","\n","    def forward(self, x):\n","        bs = x.shape[0]\n","        \n","        x = self.pool1(F.relu(self.conv1(x)))\n","        x = self.pool2(F.relu(self.conv2(x)))\n","        x = self.pool3(F.relu(self.conv3(x)))\n","        x = self.pool4(F.relu(self.conv4(x)))\n","        x = self.pool5(F.relu(self.conv5(x)))\n","\n","        x = x.view(bs, -1)\n","\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = F.relu(self.fc3(x))\n","        x = F.relu(self.fc4(x))\n","        output = self.fc_out(x)\n","        return output\n","\n","# model instance\n","model = MyNetwork()\n","\n","# Move model to GPU if available\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","# Loss function and optimizer\n","# TODO: Select a criterion and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001, amsgrad = False)\n","\n","# Learning rate scheduler\n","scheduler = ExponentialLR(optimizer = optimizer, gamma = 0.1, verbose = True)\n","\n","# Training loop\n","# TODO: Select your training epochs\n","num_epochs = 23\n","for epoch in range(num_epochs):\n","    print(f\"Epoch {epoch+1}/{num_epochs}\")\n","\n","    # Training and validation phase\n","    for phase in ['train', 'val']:\n","        if phase == 'train':\n","            model.train()\n","            dataloader = train_dataloader\n","        else:\n","            model.eval()\n","            dataloader = val_dataloader\n","\n","        running_loss = 0.0\n","        running_corrects = 0\n","\n","        for inputs, labels in tqdm(train_dataloader):\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","        \n","            # Zero the parameter gradients\n","            optimizer.zero_grad()\n","        \n","            # Forward pass through the model\n","            with torch.set_grad_enabled(phase == 'train'):\n","                outputs = model(inputs)\n","                _, preds = torch.max(outputs, 1)\n","        \n","                # Compute the loss\n","                loss = criterion(outputs, labels)\n","                \n","                # Backward + optimize\n","                if phase == 'train':\n","                    loss.backward()\n","                    optimizer.step()\n","            \n","            # Check performance\n","            running_loss += loss.item() * inputs.size(0)\n","            running_corrects += torch.sum(preds == labels.data)\n","            \n","        # Learning rate scheduler\n","        if phase == 'train':\n","            if (epoch + 1) % 7 == 0:\n","                scheduler.step()\n","\n","        epoch_loss = running_loss / len(dataloader.dataset)\n","        epoch_acc = running_corrects.double() / len(dataloader.dataset)\n","\n","        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}%')\n","\n","print('Training complete')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
